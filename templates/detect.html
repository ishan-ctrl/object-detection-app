<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Real-time Object Detection</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background: #000;
      overflow: hidden;
    }

    #video, #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    #switch-btn {
      position: absolute;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: #00b894;
      color: white;
      border: none;
      padding: 12px 20px;
      border-radius: 30px;
      font-size: 16px;
      cursor: pointer;
      z-index: 10;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <button id="switch-btn" onclick="switchCamera()">Switch Camera</button>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    let model;
    let currentFacingMode = "environment";

    async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode: currentFacingMode,
      width: { ideal: 1280 },
      height: { ideal: 720 }
    },
    audio: false
  });

      video.srcObject = stream;
      await new Promise((resolve) => {
        video.onloadedmetadata = () => resolve();
      });

      resizeCanvas();
    }

    function resizeCanvas() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    async function detectFrame() {
      if (!model) return;

      const predictions = await model.detect(video);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      predictions.forEach((pred) => {
        const [x, y, width, height] = pred.bbox;
        ctx.strokeStyle = "lime";
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, width, height);
        ctx.fillStyle = "lime";
        ctx.font = "16px sans-serif";
        ctx.fillText(
          pred.class + " - " + Math.round(pred.score * 100) + "%",
          x,
          y > 10 ? y - 5 : 10
        );
      });

      requestAnimationFrame(detectFrame);
    }

    async function switchCamera() {
      if (video.srcObject) {
        video.srcObject.getTracks().forEach((track) => track.stop());
      }

      currentFacingMode =
        currentFacingMode === "environment" ? "user" : "environment";

      await setupCamera();
      detectFrame();
    }

    async function main() {
      await setupCamera();
      model = await cocoSsd.load();
      detectFrame();
    }

    main();

    window.addEventListener("resize", resizeCanvas);
  </script>
</body>
</html>
